{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6nl2fIxQ7g-4"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score\n",
        "import random\n",
        "from tensorflow.compiler.tf2xla.python import xla"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "print(\"4 Rastgele Eğitim örnekleri ve etiketleri\")\n",
        "idx1, idx2, idx3, idx4 = random.sample(range(0, x_train.shape[0]), 4)\n",
        "\n",
        "img1 = (x_train[idx1], y_train[idx1])\n",
        "img2 = (x_train[idx2], y_train[idx2])\n",
        "img3 = (x_train[idx3], y_train[idx3])\n",
        "img4 = (x_train[idx4], y_train[idx4])\n",
        "\n",
        "imgs = [img1, img2, img3, img4]\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "for idx, item in enumerate(imgs):\n",
        "    image, label = item[0], item[1]\n",
        "    plt.subplot(2, 2, idx + 1)\n",
        "    plt.imshow(image, cmap=\"gray\")\n",
        "    plt.title(f\"Label : {label}\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        },
        "id": "IVcQIWpD7tcT",
        "outputId": "d01c2eb1-43ea-4285-8b41-cc8dce202199"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4 Rastgele Eğitim örnekleri ve etiketleri\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class FFDense(keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    A custom ForwardForward-enabled Dense layer. It has an implementation of the\n",
        "    Forward-Forward network internally for use.\n",
        "    This layer must be used in conjunction with the `FFNetwork` model.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        units,\n",
        "        optimizer,\n",
        "        loss_metric,\n",
        "        num_epochs=50,\n",
        "        use_bias=True,\n",
        "        kernel_initializer=\"glorot_uniform\",\n",
        "        bias_initializer=\"zeros\",\n",
        "        kernel_regularizer=None,\n",
        "        bias_regularizer=None,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        super().__init__(**kwargs)\n",
        "        self.dense = keras.layers.Dense(\n",
        "            units=units,\n",
        "            use_bias=use_bias,\n",
        "            kernel_initializer=kernel_initializer,\n",
        "            bias_initializer=bias_initializer,\n",
        "            kernel_regularizer=kernel_regularizer,\n",
        "            bias_regularizer=bias_regularizer,\n",
        "        )\n",
        "        self.relu = keras.layers.ReLU()\n",
        "        self.optimizer = optimizer\n",
        "        self.loss_metric = loss_metric\n",
        "        self.threshold = 1.5\n",
        "        self.num_epochs = num_epochs\n",
        "\n",
        "    # We perform a normalization step before we run the input through the Dense\n",
        "    # layer.\n",
        "\n",
        "    def call(self, x):\n",
        "        x_norm = tf.norm(x, ord=2, axis=1, keepdims=True)\n",
        "        x_norm = x_norm + 1e-4\n",
        "        x_dir = x / x_norm\n",
        "        res = self.dense(x_dir)\n",
        "        return self.relu(res)\n",
        "\n",
        "    # The Forward-Forward algorithm is below. We first perform the Dense-layer\n",
        "    # operation and then get a Mean Square value for all positive and negative\n",
        "    # samples respectively.\n",
        "    # The custom loss function finds the distance between the Mean-squared\n",
        "    # result and the threshold value we set (a hyperparameter) that will define\n",
        "    # whether the prediction is positive or negative in nature. Once the loss is\n",
        "    # calculated, we get a mean across the entire batch combined and perform a\n",
        "    # gradient calculation and optimization step. This does not technically\n",
        "    # qualify as backpropagation since there is no gradient being\n",
        "    # sent to any previous layer and is completely local in nature.\n",
        "\n",
        "    def forward_forward(self, x_pos, x_neg):\n",
        "        for i in range(self.num_epochs):\n",
        "            with tf.GradientTape() as tape:\n",
        "                g_pos = tf.math.reduce_mean(tf.math.pow(self.call(x_pos), 2), 1)\n",
        "                g_neg = tf.math.reduce_mean(tf.math.pow(self.call(x_neg), 2), 1)\n",
        "\n",
        "                loss = tf.math.log(\n",
        "                    1\n",
        "                    + tf.math.exp(\n",
        "                        tf.concat([-g_pos + self.threshold, g_neg - self.threshold], 0)\n",
        "                    )\n",
        "                )\n",
        "                mean_loss = tf.cast(tf.math.reduce_mean(loss), tf.float32)\n",
        "                self.loss_metric.update_state([mean_loss])\n",
        "            gradients = tape.gradient(mean_loss, self.dense.trainable_weights)\n",
        "            self.optimizer.apply_gradients(zip(gradients, self.dense.trainable_weights))\n",
        "        return (\n",
        "            tf.stop_gradient(self.call(x_pos)),\n",
        "            tf.stop_gradient(self.call(x_neg)),\n",
        "            self.loss_metric.result(),\n",
        "        )\n"
      ],
      "metadata": {
        "id": "lzR0ertg8emG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class FFNetwork(keras.Model):\n",
        "    \"\"\"\n",
        "    A `keras.Model` that supports a `FFDense` network creation. This model\n",
        "    can work for any kind of classification task. It has an internal\n",
        "    implementation with some details specific to the MNIST dataset which can be\n",
        "    changed as per the use-case.\n",
        "    \"\"\"\n",
        "\n",
        "    # Since each layer runs gradient-calculation and optimization locally, each\n",
        "    # layer has its own optimizer that we pass. As a standard choice, we pass\n",
        "    # the `Adam` optimizer with a default learning rate of 0.03 as that was\n",
        "    # found to be the best rate after experimentation.\n",
        "    # Loss is tracked using `loss_var` and `loss_count` variables.\n",
        "\n",
        "    def __init__(\n",
        "        self, dims, layer_optimizer=keras.optimizers.Adam(learning_rate=0.03), **kwargs\n",
        "    ):\n",
        "        super().__init__(**kwargs)\n",
        "        self.layer_optimizer = layer_optimizer\n",
        "        self.loss_var = tf.Variable(0.0, trainable=False, dtype=tf.float32)\n",
        "        self.loss_count = tf.Variable(0.0, trainable=False, dtype=tf.float32)\n",
        "        self.layer_list = [keras.Input(shape=(dims[0],))]\n",
        "        for d in range(len(dims) - 1):\n",
        "            self.layer_list += [\n",
        "                FFDense(\n",
        "                    dims[d + 1],\n",
        "                    optimizer=self.layer_optimizer,\n",
        "                    loss_metric=keras.metrics.Mean(),\n",
        "                )\n",
        "            ]\n",
        "\n",
        "    # This function makes a dynamic change to the image wherein the labels are\n",
        "    # put on top of the original image (for this example, as MNIST has 10\n",
        "    # unique labels, we take the top-left corner's first 10 pixels). This\n",
        "    # function returns the original data tensor with the first 10 pixels being\n",
        "    # a pixel-based one-hot representation of the labels.\n",
        "\n",
        "    @tf.function(reduce_retracing=True)\n",
        "    def overlay_y_on_x(self, data):\n",
        "        X_sample, y_sample = data\n",
        "        max_sample = tf.reduce_max(X_sample, axis=0, keepdims=True)\n",
        "        max_sample = tf.cast(max_sample, dtype=tf.float64)\n",
        "        X_zeros = tf.zeros([10], dtype=tf.float64)\n",
        "        X_update = xla.dynamic_update_slice(X_zeros, max_sample, [y_sample])\n",
        "        X_sample = xla.dynamic_update_slice(X_sample, X_update, [0])\n",
        "        return X_sample, y_sample\n",
        "\n",
        "    # A custom `predict_one_sample` performs predictions by passing the images\n",
        "    # through the network, measures the results produced by each layer (i.e.\n",
        "    # how high/low the output values are with respect to the set threshold for\n",
        "    # each label) and then simply finding the label with the highest values.\n",
        "    # In such a case, the images are tested for their 'goodness' with all\n",
        "    # labels.\n",
        "\n",
        "    @tf.function(reduce_retracing=True)\n",
        "    def predict_one_sample(self, x):\n",
        "        goodness_per_label = []\n",
        "        x = tf.reshape(x, [tf.shape(x)[0] * tf.shape(x)[1]])\n",
        "        for label in range(10):\n",
        "            h, label = self.overlay_y_on_x(data=(x, label))\n",
        "            h = tf.reshape(h, [-1, tf.shape(h)[0]])\n",
        "            goodness = []\n",
        "            for layer_idx in range(1, len(self.layer_list)):\n",
        "                layer = self.layer_list[layer_idx]\n",
        "                h = layer(h)\n",
        "                goodness += [tf.math.reduce_mean(tf.math.pow(h, 2), 1)]\n",
        "            goodness_per_label += [\n",
        "                tf.expand_dims(tf.reduce_sum(goodness, keepdims=True), 1)\n",
        "            ]\n",
        "        goodness_per_label = tf.concat(goodness_per_label, 1)\n",
        "        return tf.cast(tf.argmax(goodness_per_label, 1), tf.float64)\n",
        "\n",
        "    def predict(self, data):\n",
        "        x = data\n",
        "        preds = list()\n",
        "        preds = tf.map_fn(fn=self.predict_one_sample, elems=x)\n",
        "        return np.asarray(preds, dtype=int)\n",
        "\n",
        "    # This custom `train_step` function overrides the internal `train_step`\n",
        "    # implementation. We take all the input image tensors, flatten them and\n",
        "    # subsequently produce positive and negative samples on the images.\n",
        "    # A positive sample is an image that has the right label encoded on it with\n",
        "    # the `overlay_y_on_x` function. A negative sample is an image that has an\n",
        "    # erroneous label present on it.\n",
        "    # With the samples ready, we pass them through each `FFLayer` and perform\n",
        "    # the Forward-Forward computation on it. The returned loss is the final\n",
        "    # loss value over all the layers.\n",
        "\n",
        "    @tf.function(jit_compile=True)\n",
        "    def train_step(self, data):\n",
        "        x, y = data\n",
        "\n",
        "        # Flatten op\n",
        "        x = tf.reshape(x, [-1, tf.shape(x)[1] * tf.shape(x)[2]])\n",
        "\n",
        "        x_pos, y = tf.map_fn(fn=self.overlay_y_on_x, elems=(x, y))\n",
        "\n",
        "        random_y = tf.random.shuffle(y)\n",
        "        x_neg, y = tf.map_fn(fn=self.overlay_y_on_x, elems=(x, random_y))\n",
        "\n",
        "        h_pos, h_neg = x_pos, x_neg\n",
        "\n",
        "        for idx, layer in enumerate(self.layers):\n",
        "            if isinstance(layer, FFDense):\n",
        "                print(f\"Training layer {idx+1} now : \")\n",
        "                h_pos, h_neg, loss = layer.forward_forward(h_pos, h_neg)\n",
        "                self.loss_var.assign_add(loss)\n",
        "                self.loss_count.assign_add(1.0)\n",
        "            else:\n",
        "                print(f\"Passing layer {idx+1} now : \")\n",
        "                x = layer(x)\n",
        "        mean_res = tf.math.divide(self.loss_var, self.loss_count)\n",
        "        return {\"FinalLoss\": mean_res}\n"
      ],
      "metadata": {
        "id": "UeACXdxg8zP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.astype(float) / 255\n",
        "x_test = x_test.astype(float) / 255\n",
        "y_train = y_train.astype(int)\n",
        "y_test = y_test.astype(int)\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "\n",
        "train_dataset = train_dataset.batch(60000)\n",
        "test_dataset = test_dataset.batch(10000)"
      ],
      "metadata": {
        "id": "VIGguVRV8z36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = FFNetwork(dims=[784, 500, 500])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.03),\n",
        "    loss=\"mse\",\n",
        "    jit_compile=True,\n",
        "    metrics=[keras.metrics.Mean()],\n",
        ")\n",
        "\n",
        "epochs = 400\n",
        "history = model.fit(train_dataset, epochs=epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z07Zua3w8216",
        "outputId": "8f586712-9136-4db7-df3a-c7e2b8a39c0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "Training layer 1 now : \n",
            "Training layer 2 now : \n",
            "Training layer 1 now : \n",
            "Training layer 2 now : \n",
            "1/1 [==============================] - 74s 74s/step - FinalLoss: 0.7232\n",
            "Epoch 2/400\n",
            "1/1 [==============================] - 6s 6s/step - FinalLoss: 0.7063\n",
            "Epoch 3/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.6880\n",
            "Epoch 4/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.6707\n",
            "Epoch 5/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.6558\n",
            "Epoch 6/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.6427\n",
            "Epoch 7/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.6317\n",
            "Epoch 8/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.6217\n",
            "Epoch 9/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.6129\n",
            "Epoch 10/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.6050\n",
            "Epoch 11/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.5979\n",
            "Epoch 12/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.5913\n",
            "Epoch 13/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.5853\n",
            "Epoch 14/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.5795\n",
            "Epoch 15/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.5742\n",
            "Epoch 16/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.5690\n",
            "Epoch 17/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.5641\n",
            "Epoch 18/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.5594\n",
            "Epoch 19/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.5549\n",
            "Epoch 20/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.5506\n",
            "Epoch 21/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.5466\n",
            "Epoch 22/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.5427\n",
            "Epoch 23/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.5388\n",
            "Epoch 24/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.5352\n",
            "Epoch 25/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.5317\n",
            "Epoch 26/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.5283\n",
            "Epoch 27/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.5250\n",
            "Epoch 28/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.5217\n",
            "Epoch 29/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.5186\n",
            "Epoch 30/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.5156\n",
            "Epoch 31/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.5127\n",
            "Epoch 32/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.5098\n",
            "Epoch 33/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.5071\n",
            "Epoch 34/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.5044\n",
            "Epoch 35/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.5018\n",
            "Epoch 36/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4994\n",
            "Epoch 37/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4970\n",
            "Epoch 38/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4947\n",
            "Epoch 39/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4926\n",
            "Epoch 40/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4904\n",
            "Epoch 41/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4883\n",
            "Epoch 42/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4863\n",
            "Epoch 43/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4843\n",
            "Epoch 44/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4823\n",
            "Epoch 45/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4805\n",
            "Epoch 46/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4786\n",
            "Epoch 47/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4769\n",
            "Epoch 48/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4751\n",
            "Epoch 49/400\n",
            "1/1 [==============================] - 6s 6s/step - FinalLoss: 0.4735\n",
            "Epoch 50/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4718\n",
            "Epoch 51/400\n",
            "1/1 [==============================] - 6s 6s/step - FinalLoss: 0.4702\n",
            "Epoch 52/400\n",
            "1/1 [==============================] - 6s 6s/step - FinalLoss: 0.4686\n",
            "Epoch 53/400\n",
            "1/1 [==============================] - 6s 6s/step - FinalLoss: 0.4670\n",
            "Epoch 54/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4655\n",
            "Epoch 55/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4640\n",
            "Epoch 56/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4625\n",
            "Epoch 57/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4611\n",
            "Epoch 58/400\n",
            "1/1 [==============================] - 6s 6s/step - FinalLoss: 0.4597\n",
            "Epoch 59/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4583\n",
            "Epoch 60/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4569\n",
            "Epoch 61/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4556\n",
            "Epoch 62/400\n",
            "1/1 [==============================] - 6s 6s/step - FinalLoss: 0.4543\n",
            "Epoch 63/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4531\n",
            "Epoch 64/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4518\n",
            "Epoch 65/400\n",
            "1/1 [==============================] - 6s 6s/step - FinalLoss: 0.4506\n",
            "Epoch 66/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4494\n",
            "Epoch 67/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4482\n",
            "Epoch 68/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4470\n",
            "Epoch 69/400\n",
            "1/1 [==============================] - 6s 6s/step - FinalLoss: 0.4458\n",
            "Epoch 70/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4447\n",
            "Epoch 71/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4436\n",
            "Epoch 72/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4426\n",
            "Epoch 73/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4415\n",
            "Epoch 74/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4405\n",
            "Epoch 75/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4394\n",
            "Epoch 76/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4384\n",
            "Epoch 77/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4374\n",
            "Epoch 78/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4364\n",
            "Epoch 79/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4354\n",
            "Epoch 80/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4345\n",
            "Epoch 81/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4335\n",
            "Epoch 82/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4326\n",
            "Epoch 83/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4317\n",
            "Epoch 84/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4308\n",
            "Epoch 85/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4299\n",
            "Epoch 86/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4290\n",
            "Epoch 87/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4281\n",
            "Epoch 88/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4273\n",
            "Epoch 89/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4264\n",
            "Epoch 90/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4256\n",
            "Epoch 91/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4247\n",
            "Epoch 92/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4239\n",
            "Epoch 93/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4231\n",
            "Epoch 94/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4224\n",
            "Epoch 95/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4216\n",
            "Epoch 96/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4208\n",
            "Epoch 97/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4200\n",
            "Epoch 98/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4193\n",
            "Epoch 99/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4185\n",
            "Epoch 100/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4178\n",
            "Epoch 101/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4171\n",
            "Epoch 102/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4163\n",
            "Epoch 103/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4156\n",
            "Epoch 104/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4149\n",
            "Epoch 105/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4142\n",
            "Epoch 106/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4135\n",
            "Epoch 107/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4128\n",
            "Epoch 108/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4122\n",
            "Epoch 109/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4115\n",
            "Epoch 110/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4108\n",
            "Epoch 111/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4102\n",
            "Epoch 112/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4096\n",
            "Epoch 113/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4089\n",
            "Epoch 114/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4083\n",
            "Epoch 115/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4077\n",
            "Epoch 116/400\n",
            "1/1 [==============================] - 6s 6s/step - FinalLoss: 0.4071\n",
            "Epoch 117/400\n",
            "1/1 [==============================] - 6s 6s/step - FinalLoss: 0.4065\n",
            "Epoch 118/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4059\n",
            "Epoch 119/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4053\n",
            "Epoch 120/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4047\n",
            "Epoch 121/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4041\n",
            "Epoch 122/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4035\n",
            "Epoch 123/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4030\n",
            "Epoch 124/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4024\n",
            "Epoch 125/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4018\n",
            "Epoch 126/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4013\n",
            "Epoch 127/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4007\n",
            "Epoch 128/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.4002\n",
            "Epoch 129/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3996\n",
            "Epoch 130/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3991\n",
            "Epoch 131/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3986\n",
            "Epoch 132/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3981\n",
            "Epoch 133/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3975\n",
            "Epoch 134/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3970\n",
            "Epoch 135/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3965\n",
            "Epoch 136/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3961\n",
            "Epoch 137/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3956\n",
            "Epoch 138/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3951\n",
            "Epoch 139/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3946\n",
            "Epoch 140/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3941\n",
            "Epoch 141/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3937\n",
            "Epoch 142/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3932\n",
            "Epoch 143/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3927\n",
            "Epoch 144/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3923\n",
            "Epoch 145/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3918\n",
            "Epoch 146/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3914\n",
            "Epoch 147/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3909\n",
            "Epoch 148/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3905\n",
            "Epoch 149/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3901\n",
            "Epoch 150/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3896\n",
            "Epoch 151/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3892\n",
            "Epoch 152/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3888\n",
            "Epoch 153/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3884\n",
            "Epoch 154/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3879\n",
            "Epoch 155/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3875\n",
            "Epoch 156/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3871\n",
            "Epoch 157/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3867\n",
            "Epoch 158/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3863\n",
            "Epoch 159/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3859\n",
            "Epoch 160/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3855\n",
            "Epoch 161/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3851\n",
            "Epoch 162/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3847\n",
            "Epoch 163/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3843\n",
            "Epoch 164/400\n",
            "1/1 [==============================] - 6s 6s/step - FinalLoss: 0.3839\n",
            "Epoch 165/400\n",
            "1/1 [==============================] - 6s 6s/step - FinalLoss: 0.3835\n",
            "Epoch 166/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3831\n",
            "Epoch 167/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3828\n",
            "Epoch 168/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3824\n",
            "Epoch 169/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3821\n",
            "Epoch 170/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3817\n",
            "Epoch 171/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3813\n",
            "Epoch 172/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3810\n",
            "Epoch 173/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3806\n",
            "Epoch 174/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3802\n",
            "Epoch 175/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3799\n",
            "Epoch 176/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3796\n",
            "Epoch 177/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3792\n",
            "Epoch 178/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3789\n",
            "Epoch 179/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3785\n",
            "Epoch 180/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3782\n",
            "Epoch 181/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3778\n",
            "Epoch 182/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3775\n",
            "Epoch 183/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3772\n",
            "Epoch 184/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3769\n",
            "Epoch 185/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3765\n",
            "Epoch 186/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3762\n",
            "Epoch 187/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3759\n",
            "Epoch 188/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3756\n",
            "Epoch 189/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3752\n",
            "Epoch 190/400\n",
            "1/1 [==============================] - 6s 6s/step - FinalLoss: 0.3749\n",
            "Epoch 191/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3746\n",
            "Epoch 192/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3743\n",
            "Epoch 193/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3740\n",
            "Epoch 194/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3737\n",
            "Epoch 195/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3734\n",
            "Epoch 196/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3731\n",
            "Epoch 197/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3728\n",
            "Epoch 198/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3725\n",
            "Epoch 199/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3722\n",
            "Epoch 200/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3719\n",
            "Epoch 201/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3716\n",
            "Epoch 202/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3713\n",
            "Epoch 203/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3710\n",
            "Epoch 204/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3708\n",
            "Epoch 205/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3705\n",
            "Epoch 206/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3702\n",
            "Epoch 207/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3699\n",
            "Epoch 208/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3696\n",
            "Epoch 209/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3694\n",
            "Epoch 210/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3691\n",
            "Epoch 211/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3688\n",
            "Epoch 212/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3686\n",
            "Epoch 213/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3683\n",
            "Epoch 214/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3680\n",
            "Epoch 215/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3678\n",
            "Epoch 216/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3675\n",
            "Epoch 217/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3672\n",
            "Epoch 218/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3670\n",
            "Epoch 219/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3667\n",
            "Epoch 220/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3664\n",
            "Epoch 221/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3662\n",
            "Epoch 222/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3659\n",
            "Epoch 223/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3657\n",
            "Epoch 224/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3654\n",
            "Epoch 225/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3652\n",
            "Epoch 226/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3649\n",
            "Epoch 227/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3647\n",
            "Epoch 228/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3644\n",
            "Epoch 229/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3642\n",
            "Epoch 230/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3639\n",
            "Epoch 231/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3637\n",
            "Epoch 232/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3635\n",
            "Epoch 233/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3632\n",
            "Epoch 234/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3630\n",
            "Epoch 235/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3627\n",
            "Epoch 236/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3625\n",
            "Epoch 237/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3623\n",
            "Epoch 238/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3621\n",
            "Epoch 239/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3618\n",
            "Epoch 240/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3616\n",
            "Epoch 241/400\n",
            "1/1 [==============================] - 6s 6s/step - FinalLoss: 0.3614\n",
            "Epoch 242/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3612\n",
            "Epoch 243/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3609\n",
            "Epoch 244/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3607\n",
            "Epoch 245/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3605\n",
            "Epoch 246/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3603\n",
            "Epoch 247/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3601\n",
            "Epoch 248/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3599\n",
            "Epoch 249/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3597\n",
            "Epoch 250/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3594\n",
            "Epoch 251/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3592\n",
            "Epoch 252/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3590\n",
            "Epoch 253/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3588\n",
            "Epoch 254/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3586\n",
            "Epoch 255/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3584\n",
            "Epoch 256/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3582\n",
            "Epoch 257/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3580\n",
            "Epoch 258/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3578\n",
            "Epoch 259/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3576\n",
            "Epoch 260/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3574\n",
            "Epoch 261/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3572\n",
            "Epoch 262/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3570\n",
            "Epoch 263/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3568\n",
            "Epoch 264/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3566\n",
            "Epoch 265/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3564\n",
            "Epoch 266/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3562\n",
            "Epoch 267/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3560\n",
            "Epoch 268/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3558\n",
            "Epoch 269/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3557\n",
            "Epoch 270/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3555\n",
            "Epoch 271/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3553\n",
            "Epoch 272/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3551\n",
            "Epoch 273/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3549\n",
            "Epoch 274/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3547\n",
            "Epoch 275/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3546\n",
            "Epoch 276/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3544\n",
            "Epoch 277/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3542\n",
            "Epoch 278/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3540\n",
            "Epoch 279/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3538\n",
            "Epoch 280/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3536\n",
            "Epoch 281/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3535\n",
            "Epoch 282/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3533\n",
            "Epoch 283/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3531\n",
            "Epoch 284/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3529\n",
            "Epoch 285/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3528\n",
            "Epoch 286/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3526\n",
            "Epoch 287/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3524\n",
            "Epoch 288/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3522\n",
            "Epoch 289/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3521\n",
            "Epoch 290/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3519\n",
            "Epoch 291/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3517\n",
            "Epoch 292/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3516\n",
            "Epoch 293/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3514\n",
            "Epoch 294/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3512\n",
            "Epoch 295/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3511\n",
            "Epoch 296/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3509\n",
            "Epoch 297/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3507\n",
            "Epoch 298/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3506\n",
            "Epoch 299/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3504\n",
            "Epoch 300/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3503\n",
            "Epoch 301/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3501\n",
            "Epoch 302/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3499\n",
            "Epoch 303/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3498\n",
            "Epoch 304/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3496\n",
            "Epoch 305/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3495\n",
            "Epoch 306/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3493\n",
            "Epoch 307/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3492\n",
            "Epoch 308/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3490\n",
            "Epoch 309/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3489\n",
            "Epoch 310/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3487\n",
            "Epoch 311/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3486\n",
            "Epoch 312/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3484\n",
            "Epoch 313/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3483\n",
            "Epoch 314/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3481\n",
            "Epoch 315/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3480\n",
            "Epoch 316/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3478\n",
            "Epoch 317/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3477\n",
            "Epoch 318/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3476\n",
            "Epoch 319/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3474\n",
            "Epoch 320/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3473\n",
            "Epoch 321/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3471\n",
            "Epoch 322/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3470\n",
            "Epoch 323/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3468\n",
            "Epoch 324/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3467\n",
            "Epoch 325/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3466\n",
            "Epoch 326/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3464\n",
            "Epoch 327/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3463\n",
            "Epoch 328/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3461\n",
            "Epoch 329/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3460\n",
            "Epoch 330/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3459\n",
            "Epoch 331/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3457\n",
            "Epoch 332/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3456\n",
            "Epoch 333/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3455\n",
            "Epoch 334/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3453\n",
            "Epoch 335/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3452\n",
            "Epoch 336/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3451\n",
            "Epoch 337/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3449\n",
            "Epoch 338/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3448\n",
            "Epoch 339/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3446\n",
            "Epoch 340/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3445\n",
            "Epoch 341/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3444\n",
            "Epoch 342/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3443\n",
            "Epoch 343/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3441\n",
            "Epoch 344/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3440\n",
            "Epoch 345/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3439\n",
            "Epoch 346/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3437\n",
            "Epoch 347/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3436\n",
            "Epoch 348/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3435\n",
            "Epoch 349/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3433\n",
            "Epoch 350/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3432\n",
            "Epoch 351/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3431\n",
            "Epoch 352/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3430\n",
            "Epoch 353/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3428\n",
            "Epoch 354/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3427\n",
            "Epoch 355/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3426\n",
            "Epoch 356/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3425\n",
            "Epoch 357/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3424\n",
            "Epoch 358/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3422\n",
            "Epoch 359/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3421\n",
            "Epoch 360/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3420\n",
            "Epoch 361/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3419\n",
            "Epoch 362/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3418\n",
            "Epoch 363/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3417\n",
            "Epoch 364/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3415\n",
            "Epoch 365/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3414\n",
            "Epoch 366/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3413\n",
            "Epoch 367/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3412\n",
            "Epoch 368/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3411\n",
            "Epoch 369/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3410\n",
            "Epoch 370/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3409\n",
            "Epoch 371/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3407\n",
            "Epoch 372/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3406\n",
            "Epoch 373/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3405\n",
            "Epoch 374/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3404\n",
            "Epoch 375/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3403\n",
            "Epoch 376/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3402\n",
            "Epoch 377/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3401\n",
            "Epoch 378/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3400\n",
            "Epoch 379/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3398\n",
            "Epoch 380/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3397\n",
            "Epoch 381/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3396\n",
            "Epoch 382/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3395\n",
            "Epoch 383/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3394\n",
            "Epoch 384/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3393\n",
            "Epoch 385/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3392\n",
            "Epoch 386/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3391\n",
            "Epoch 387/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3390\n",
            "Epoch 388/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3389\n",
            "Epoch 389/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3388\n",
            "Epoch 390/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3387\n",
            "Epoch 391/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3386\n",
            "Epoch 392/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3384\n",
            "Epoch 393/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3383\n",
            "Epoch 394/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3382\n",
            "Epoch 395/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3381\n",
            "Epoch 396/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3380\n",
            "Epoch 397/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3379\n",
            "Epoch 398/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3378\n",
            "Epoch 399/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3377\n",
            "Epoch 400/400\n",
            "1/1 [==============================] - 5s 5s/step - FinalLoss: 0.3376\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model.predict(tf.convert_to_tensor(x_test))\n",
        "\n",
        "preds = preds.reshape((preds.shape[0], preds.shape[1]))\n",
        "\n",
        "results = accuracy_score(preds, y_test)\n",
        "\n",
        "print(f\"Test Accuracy score : {results*100}%\")\n",
        "\n",
        "plt.plot(range(len(history.history[\"FinalLoss\"])), history.history[\"FinalLoss\"])\n",
        "plt.title(\"Loss over training\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "yPD2wdQy9Ar6",
        "outputId": "dc7afff3-3000-43bd-8d4d-aeda53f6bd4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy score : 88.86%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}